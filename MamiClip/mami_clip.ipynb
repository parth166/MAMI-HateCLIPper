{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUK6eYhLPLq0",
        "outputId": "12d0dc5a-18e6-49a4-928f-97011a87d430"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 614188219315928546\n",
              " xla_global_id: -1,\n",
              " name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 14343274496\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 17151689243788592156\n",
              " physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
              " xla_global_id: 416903419]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TROlJZ1N-YZo",
        "outputId": "f2c1bf64-f346-4c58-e2a6-93cf5d3f578b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.1+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n",
            "Requirement already satisfied: torch==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.0.0+cu118)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchvision) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->torchvision) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->torchvision) (16.0.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0->torchvision) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0->torchvision) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.10.1)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.22.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ekphrasis\n",
            "  Downloading ekphrasis-0.5.4-py3-none-any.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.8/83.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from ekphrasis) (2.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from ekphrasis) (4.65.0)\n",
            "Collecting colorama (from ekphrasis)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting ujson (from ekphrasis)\n",
            "  Downloading ujson-5.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from ekphrasis) (3.7.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from ekphrasis) (3.8.1)\n",
            "Collecting ftfy (from ekphrasis)\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ekphrasis) (1.22.4)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->ekphrasis) (0.2.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->ekphrasis) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->ekphrasis) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->ekphrasis) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->ekphrasis) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->ekphrasis) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->ekphrasis) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->ekphrasis) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->ekphrasis) (2.8.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->ekphrasis) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->ekphrasis) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->ekphrasis) (2022.10.31)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->ekphrasis) (1.16.0)\n",
            "Installing collected packages: ujson, ftfy, colorama, ekphrasis\n",
            "Successfully installed colorama-0.4.6 ekphrasis-0.5.4 ftfy-6.1.1 ujson-5.7.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai-clip\n",
            "  Downloading openai-clip-1.0.1.tar.gz (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from openai-clip) (6.1.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from openai-clip) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-clip) (4.65.0)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy->openai-clip) (0.2.6)\n",
            "Building wheels for collected packages: openai-clip\n",
            "  Building wheel for openai-clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-clip: filename=openai_clip-1.0.1-py3-none-any.whl size=1368607 sha256=65c655ef5a66cd01d6302cd4071d18b47ccd3bd7c5e9b93a69aee0be8a6e7333\n",
            "  Stored in directory: /root/.cache/pip/wheels/08/77/8e/8d2f862df6bf7fb4e2007062d2cbaeae49862ec7b56d041229\n",
            "Successfully built openai-clip\n",
            "Installing collected packages: openai-clip\n",
            "Successfully installed openai-clip-1.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install scikit-learn\n",
        "!pip install scipy\n",
        "!pip install ekphrasis\n",
        "!pip install openai-clip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsGaKqwzAEzW",
        "outputId": "47b8b958-f6f5-4f27-bf74-422c698386e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2e5DIOvl1wVJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import clip\n",
        "import torch.optim as optim\n",
        "import time\n",
        "from sklearn import metrics\n",
        "import argparse\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "import torch\n",
        "import sys\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Insert the directory\n",
        "sys.path.insert(0,'/content/drive/MyDrive/MamiGit/mami')\n",
        "import random\n",
        "from helper_functions import *\n",
        "from text_normalizer import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "MGilUxzFVdDG",
        "outputId": "a9cf0d88-f1e3-46c6-b310-95d8810e26ba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import os\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9JCRp7Qey5Y6"
      },
      "outputs": [],
      "source": [
        "## Dataset Loading\n",
        "# tr_df = pd.read_csv('/content/drive/MyDrive/MamiProject/files/small_training.csv', sep=',') # use '/t' for main training data\n",
        "# tr_df = pd.read_csv('/content/drive/MyDrive/MamiProject/files/training.csv', sep='\\t') # use '/t' for main training data\n",
        "tr_df = pd.read_csv('/content/drive/MyDrive/MamiGit/mami/data/train.tsv', sep='\\t') # use '/t' for main training data\n",
        "# tr_df = tr_df.head(100)\n",
        "vl_df = pd.read_csv('/content/drive/MyDrive/MamiGit/mami/data/validation.tsv', sep='\\t') # use '/t' for main training data\n",
        "# vl_df = vl_df.head(100)\n",
        "ts_df = pd.read_csv('/content/drive/MyDrive/MamiGit/mami/data/test.tsv', sep='\\t') # use '/t' for main training data\n",
        "# ts_df = ts_df.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUlVsBuefrMT",
        "outputId": "a17ca2b5-cafe-4abc-aa11-cb5fd9a565e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   file_name  label  shaming  stereotype  objectification  violence  \\\n",
            "0   8716.jpg      1        0           1                1         0   \n",
            "1   3066.jpg      1        1           1                0         0   \n",
            "2   6038.jpg      0        0           0                0         0   \n",
            "3  10861.jpg      1        0           0                1         0   \n",
            "4  11198.jpg      0        0           0                0         0   \n",
            "\n",
            "                                                text  \n",
            "0  GETS MARRIED TO GIRL OF HIS DREAMS SHE DOESN'T...  \n",
            "1  When your mama don't change yo diaper for 19 y...  \n",
            "2  Some people want a big house, a fast car, and ...  \n",
            "3     FAP FAP FAP FAP FAP FAP memecenter Meme Center  \n",
            "4              I RAISE. A I CALL. I FOLD. I'M ALL IN  \n"
          ]
        }
      ],
      "source": [
        "print(tr_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4WIqQC918DE",
        "outputId": "07759737-3561-429f-fdaa-39799e0939cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['file_name', 'label', 'shaming', 'stereotype', 'objectification', 'violence', 'text']\n"
          ]
        }
      ],
      "source": [
        "tr_df.rename(columns = {'Text Transcription':'text'}, inplace = True)\n",
        "tr_df.rename(columns = {'misogynous':'label'}, inplace = True)\n",
        "\n",
        "my_list = tr_df.columns.values.tolist()\n",
        "print (my_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLSCo--iCYl4",
        "outputId": "11cf1dbb-07d8-4a16-d11f-27a9fd1167cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  file_name  label  shaming  stereotype  objectification  violence  \\\n",
            "0  1377.jpg      1        0           1                0         0   \n",
            "1  5498.jpg      1        0           1                0         0   \n",
            "2  5697.jpg      1        0           1                0         0   \n",
            "3  5182.jpg      1        0           0                0         0   \n",
            "4  6162.jpg      1        0           1                0         0   \n",
            "\n",
            "                                                text  \n",
            "0  IF WOMEN WANT EQUAL PAY THEY SHOULD DO EQUAL W...  \n",
            "1                  IF A WOMAN WERE TO DRIVE YOUR CAR  \n",
            "2                           When a woman is a driver  \n",
            "3  SEXY BITCHES? Ba GIVE THEM BACON TO MAKE THEM ...  \n",
            "4  When you reach peak feminism FEMINIST Just Bec...  \n",
            "1000\n"
          ]
        }
      ],
      "source": [
        "print(vl_df.head())\n",
        "print(len(vl_df))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jhr0ETrSn21e",
        "outputId": "b69d2a51-0d00-4d30-ccc7-fcf256eb9ff6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method NDFrame.head of      file_name  label  shaming  stereotype  objectification  violence  \\\n",
            "0    15236.jpg      0        0           0                0         0   \n",
            "1    15805.jpg      1        0           1                1         0   \n",
            "2    16254.jpg      0        0           0                0         0   \n",
            "3    16191.jpg      1        0           1                1         0   \n",
            "4    15952.jpg      0        0           0                0         0   \n",
            "..         ...    ...      ...         ...              ...       ...   \n",
            "995  15591.jpg      1        0           1                1         0   \n",
            "996  15049.jpg      0        0           0                0         0   \n",
            "997  15363.jpg      1        0           1                1         0   \n",
            "998  15199.jpg      0        0           0                0         0   \n",
            "999  15853.jpg      0        0           0                0         0   \n",
            "\n",
            "                                                  text  \n",
            "0    FACEBOOK SINGLES GROUPS BELIKE WHEN A NEW WOMA...  \n",
            "1      SO, IF YOU'RE A FEMINIST HOW CAN YOU EAT DAIRY?  \n",
            "2           WHEN A CUTE GIRL LEFT YOUR MESSAGE ON SEEN  \n",
            "3    Photographing something you want to show every...  \n",
            "4    HEY BABE CAN YOU MAKE ME A SANDWICH? Hey babe ...  \n",
            "..                                                 ...  \n",
            "995  IT'S NOT YOUR FAULT You didn't design the dres...  \n",
            "996  THINK ABOUT HOW MUCH BETTER HER SKIN IS BREATH...  \n",
            "997  THE STEREOTYPES ARE TRUE F SHE DOES HAVE A TIG...  \n",
            "998  DRAWS NAKED PICTURES OF BLACK WOMEN 00 0000 GE...  \n",
            "999  \"You work too much.\" Me: OOL I want to be rich...  \n",
            "\n",
            "[1000 rows x 7 columns]>\n"
          ]
        }
      ],
      "source": [
        "print(ts_df.head)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_tXqzEFisJls"
      },
      "outputs": [],
      "source": [
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "# Arguments\n",
        "batch_size=64\n",
        "init_lr=1e-4\n",
        "epochs=10\n",
        "max_length=77\n",
        "lr=1e-5\n",
        "vmodel='vit14'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QM3j8pA9YDK",
        "outputId": "bb0f4ad5-fda8-4ca4-a006-a6cebe8aab7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 890M/890M [00:10<00:00, 91.9MiB/s]\n"
          ]
        }
      ],
      "source": [
        "## Pre-trained Stream Models\n",
        "clip_nms = {'vit14':'ViT-L/14'}\n",
        "clip_dim = {'vit14': 768}\n",
        "clip_model, _ = clip.load(clip_nms[vmodel],jit=False)\n",
        "input_resolution = clip_model.visual.input_resolution\n",
        "clip_model.float().eval()\n",
        "clip_model = nn.DataParallel(clip_model)\n",
        "dim = clip_dim[vmodel]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "t03vu9Fb7RK_"
      },
      "outputs": [],
      "source": [
        "## Transforms\n",
        "transform_config = {'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(input_resolution, interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        # transforms.ColorJitter(brightness=0.2, contrast=0.1, saturation=0.1, hue=0.2),\n",
        "        transforms.RandomGrayscale(p=0.1),\n",
        "        # transforms.RandomPerspective(),\n",
        "        transforms.RandomRotation(degrees=10),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073],\n",
        "                                    std=[0.26862954, 0.26130258, 0.27577711])\n",
        "    ]), \n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize((input_resolution,input_resolution), interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "        # transforms.CenterCrop(clip_model.visual.input_resolution),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073],\n",
        "                                    std=[0.26862954, 0.26130258, 0.27577711])\n",
        "    ])\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "UGdeZ-DAij7F"
      },
      "outputs": [],
      "source": [
        "# !pip install simpletokenizer\n",
        "# import simpletokenizer as _Tokenizer\n",
        "\n",
        "from clip.simple_tokenizer import SimpleTokenizer\n",
        "_tokenizer = SimpleTokenizer()\n",
        "\n",
        "def tokenize(text, context_length: int = 77):\n",
        "\n",
        "    sot_token = _tokenizer.encoder[\"<|startoftext|>\"]\n",
        "    eot_token = _tokenizer.encoder[\"<|endoftext|>\"]\n",
        "    # all_tokens = _tokenizer.encode(text)\n",
        "    tokens = [sot_token] + _tokenizer.encode(text)[:context_length-2] + [eot_token]\n",
        "    result = torch.zeros(context_length, dtype=torch.long)\n",
        "    mask = torch.zeros(context_length, dtype=torch.long)\n",
        "    result[:len(tokens)] = torch.tensor(tokens)\n",
        "    mask[:len(tokens)] = 1\n",
        "\n",
        "    return result, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "uKubVso48ZaT"
      },
      "outputs": [],
      "source": [
        "## Dataset\n",
        "tr_data = CustomDatasetFixed(tr_df, 'training', transform_config['test'], preprocess, tokenize, max_length)\n",
        "vl_data = CustomDatasetFixed(vl_df, 'training', transform_config['test'], preprocess, tokenize, max_length)\n",
        "ts_data = CustomDatasetFixed(ts_df, 'test', transform_config['test'], preprocess, tokenize, max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlV3gJ0Rh8ni",
        "outputId": "56fba925-f72b-47cb-b710-38221c976e9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<helper_functions.CustomDatasetFixed object at 0x7efe9a761900>\n"
          ]
        }
      ],
      "source": [
        "print(tr_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "BL-an3UJuqz0"
      },
      "outputs": [],
      "source": [
        "class MMNetwork(nn.Module):\n",
        "    def __init__(self, vdim, tdim, n_cls):\n",
        "        super(MMNetwork, self).__init__()\n",
        "        # print(\"vdim\", vdim)\n",
        "        # print(\"tdim\", tdim)\n",
        "        ## Linear layer for ResNet features\n",
        "        self.vfc = nn.Linear(vdim, 256)\n",
        "\n",
        "        ## Single Layer Bi-directional RNN with GRU cells. Projects 768 to 512 \n",
        "        self.bigru = nn.LSTM(tdim, 256, 1, bidirectional=False, batch_first=True, bias=False)\n",
        "\n",
        "        ## Concatenated Image and Text goes through this multi-layer network\n",
        "        self.mfc1 = nn.Linear(512, 256)\n",
        "        # self.mfc2 = nn.Linear(512, 256)\n",
        "        # self.mfc3 = nn.Linear(256, 128)\n",
        "        # self.mfc4 = nn.Linear(256, 128)\n",
        "\n",
        "        self.cf1 = nn.Linear(256, 1)\n",
        "        self.cf2 = nn.Linear(256, 1)\n",
        "        self.cf3 = nn.Linear(256, 1)\n",
        "        self.cf4 = nn.Linear(256, 1)\n",
        "        self.cf5 = nn.Linear(256, 1)\n",
        "\n",
        "\n",
        "        self.act = nn.ReLU()    ## ReLU\n",
        "        self.vdp = nn.Dropout(0.2)\n",
        "        self.tdp = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, vx, tx, masks=None):\n",
        "        vx = self.vdp(self.act(self.vfc(vx)))\n",
        "        hidden_tx,_ = self.bigru(tx)\n",
        "        # Concatenate Visual and Textual output\n",
        "        mx = torch.cat((vx, self.tdp(hidden_tx)), dim=1) # changed this\n",
        "\n",
        "        mx = self.act(self.mfc1(mx))\n",
        "        # mx = self.act(self.mfc2(mx))\n",
        "        # mx = self.relu(self.mfc3(mx))\n",
        "        # mx = self.relu(self.mfc4(mx))\n",
        "\n",
        "        return torch.sigmoid(self.cf1(mx)), torch.sigmoid(self.cf2(mx)), torch.sigmoid(self.cf3(mx)), \\\n",
        "                torch.sigmoid(self.cf4(mx)), torch.sigmoid(self.cf5(mx))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "l6DesBgMGxSW"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, loader, test_flag):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    all_preds1 = []\n",
        "    all_labels1 = []\n",
        "    all_preds2 = []\n",
        "    all_labels2 = []\n",
        "    all_preds3 = []\n",
        "    all_labels3 = []\n",
        "    all_preds4 = []\n",
        "    all_labels4 = []\n",
        "    all_preds5 = []\n",
        "    all_labels5 = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for img_inps, txt_tokens, masks, labels1, labels2, labels3, labels4, labels5 in loader:\n",
        "\n",
        "            img_inps, txt_tokens, masks, labels1, labels2, labels3, labels4, labels5 = img_inps.to(device), \\\n",
        "                txt_tokens.to(device), masks.to(device), labels1.to(device), labels2.to(device), labels3.to(device), \\\n",
        "                labels4.to(device), labels5.to(device)\n",
        "\n",
        "            img_feats = clip_model.module.encode_image(img_inps)\n",
        "            txt_feats = clip_model.module.encode_text(txt_tokens) # changed this\n",
        "            # _, txt_feats = clip_model.module.encode_text(txt_tokens)\n",
        "\n",
        "            outputs1, outputs2, outputs3, outputs4, outputs5 = model(img_feats, txt_feats, masks)\n",
        "\n",
        "            preds1 = (outputs1>0.5).int()\n",
        "            preds2 = (outputs2>0.5).int()\n",
        "            preds3 = (outputs3>0.5).int()\n",
        "            preds4 = (outputs4>0.5).int()\n",
        "            preds5 = (outputs5>0.5).int()\n",
        "            \n",
        "            test_loss += (criterion(outputs1, labels1.unsqueeze(1).float()).item() + criterion(outputs2, labels2.unsqueeze(1).float()).item() + \\\n",
        "                            criterion(outputs3, labels3.unsqueeze(1).float()).item() + criterion(outputs4, labels4.unsqueeze(1).float()).item() + \\\n",
        "                            criterion(outputs5, labels5.unsqueeze(1).float()).item())\n",
        "\n",
        "            all_preds1.extend(preds1.cpu().numpy().flatten())\n",
        "            all_labels1.extend(labels1.cpu().numpy().flatten())\n",
        "            all_preds2.extend(preds2.cpu().numpy().flatten())\n",
        "            all_labels2.extend(labels2.cpu().numpy().flatten())\n",
        "            all_preds3.extend(preds3.cpu().numpy().flatten())\n",
        "            all_labels3.extend(labels3.cpu().numpy().flatten())\n",
        "            all_preds4.extend(preds4.cpu().numpy().flatten())\n",
        "            all_labels4.extend(labels4.cpu().numpy().flatten())\n",
        "            all_preds5.extend(preds5.cpu().numpy().flatten())\n",
        "            all_labels5.extend(labels5.cpu().numpy().flatten())\n",
        "\n",
        "        acc = metrics.accuracy_score(all_labels1, all_preds1)\n",
        "        f1_1 = metrics.f1_score(all_labels1, all_preds1, average='macro')\n",
        "        f1_2 = metrics.f1_score(all_labels2, all_preds2, average='macro')\n",
        "        f1_3 = metrics.f1_score(all_labels3, all_preds3, average='macro')\n",
        "        f1_4 = metrics.f1_score(all_labels4, all_preds4, average='macro')\n",
        "        f1_5 = metrics.f1_score(all_labels5, all_preds5, average='macro')\n",
        "\n",
        "        #Get all the incorrect predictions\n",
        "        if(test_flag):\n",
        "          # Open a file to write the indexes of non-matching labels\n",
        "          with open('/content/drive/MyDrive/non_matching_indexes.txt', 'w') as f:\n",
        "            # Loop through the indexes of the labels in the first list\n",
        "            for i in range(len(all_labels1)): \n",
        "              # Check if the label in the first list does not match the label in the second list\n",
        "              if all_labels1[i] != all_preds1[i]:\n",
        "                # Write the index to the file\n",
        "                f.write(str(i) + '\\n')\n",
        "    return test_loss/len(loader), acc, f1_1, f1_2, f1_3, f1_4, f1_5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "flvJvpeDvfAO"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, lr_scheduler, num_epochs):\n",
        "    test_flag=False\n",
        "    since = time.time()\n",
        "\n",
        "    best_model = model\n",
        "    best_acc = 0.0\n",
        "    best_val_loss = 100\n",
        "    best_epoch = 0\n",
        "    best_f1 = 0\n",
        "\n",
        "    for epoch in range(1, num_epochs+1):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        since2 = time.time()\n",
        "\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        tot = 0.0\n",
        "        cnt = 0\n",
        "        # Iterate over data.\n",
        "        for img_inps, txt_tokens, masks, labels1, labels2, labels3, labels4, labels5 in tr_loader:\n",
        "\n",
        "            img_inps, txt_tokens, masks, labels1, labels2, labels3, labels4, labels5 = img_inps.to(device), \\\n",
        "                txt_tokens.to(device), masks.to(device), labels1.to(device), labels2.to(device), labels3.to(device), \\\n",
        "                labels4.to(device), labels5.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "            # forward\n",
        "            with torch.no_grad():\n",
        "                img_feats = clip_model.module.encode_image(img_inps)\n",
        "                txt_feats = clip_model.module.encode_text(txt_tokens) # changed this\n",
        "\n",
        "            outputs1, outputs2, outputs3, outputs4, outputs5 = model(img_feats, txt_feats, masks)\n",
        "            preds1 = (outputs1>0.5).int()\n",
        "\n",
        "            loss = criterion(outputs1, labels1.unsqueeze(1).float()) + criterion(outputs2, labels2.unsqueeze(1).float()) + \\\n",
        "                    criterion(outputs3, labels3.unsqueeze(1).float()) + criterion(outputs4, labels4.unsqueeze(1).float()) + \\\n",
        "                    criterion(outputs5, labels5.unsqueeze(1).float())\n",
        "\n",
        "            # backward + optimize\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            # statistics\n",
        "            running_loss += loss.item()\n",
        "            running_corrects += torch.sum(preds1 == labels1.data.view_as(preds1)).item()\n",
        "            tot += len(labels1)\n",
        "\n",
        "            if cnt % 40 == 0:\n",
        "                print('[%d, %5d] loss: %.4f, Acc: %.2f' %\n",
        "                      (epoch, cnt + 1, loss.item(), (100.0 * running_corrects) / tot))\n",
        "\n",
        "            cnt = cnt + 1\n",
        "\n",
        "        if scheduler:\n",
        "            lr_scheduler.step()\n",
        "\n",
        "\n",
        "        train_loss = running_loss / len(tr_loader)\n",
        "        train_acc = running_corrects * 1.0 / (len(tr_loader.dataset))\n",
        "\n",
        "        print('Training Loss: {:.6f} Acc: {:.2f}'.format(train_loss, 100.0 * train_acc))\n",
        "\n",
        "        test_loss, test_acc, test_f1_1, test_f1_2, test_f1_3, test_f1_4, test_f1_5 = evaluate(model, vl_loader, test_flag)\n",
        "\n",
        "        print('Epoch: {:d}, Val Loss: {:.4f}, Acc: {:.2f}, F1_1: {:.2f}, F1_2: {:.2f}, F1_3: {:.2f}, F1_4: {:.2f}, F1_5: {:.2f}'.format(epoch, test_loss,test_acc*100, test_f1_1*100, test_f1_2*100, \\\n",
        "                 test_f1_3*100, test_f1_4*100, test_f1_5*100))\n",
        "\n",
        "\n",
        "        # deep copy the model\n",
        "        if test_f1_1 >= best_f1:\n",
        "            best_acc = test_acc\n",
        "            best_val_loss = test_loss\n",
        "            best_model = copy.deepcopy(model)\n",
        "            best_epoch = epoch\n",
        "            best_f1 = test_f1_1\n",
        "\n",
        "    time_elapsed2 = time.time() - since2\n",
        "    print('Epoch complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed2 // 60, time_elapsed2 % 60))\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "\n",
        "    return best_model, best_epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_Vexu2epQxm",
        "outputId": "cdde8cf5-b19a-4962-f721-f4d8a3614c7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MMNetwork(\n",
            "  (vfc): Linear(in_features=768, out_features=256, bias=True)\n",
            "  (bigru): LSTM(768, 256, bias=False, batch_first=True)\n",
            "  (mfc1): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (cf1): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (cf2): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (cf3): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (cf4): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (cf5): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (act): ReLU()\n",
            "  (vdp): Dropout(p=0.2, inplace=False)\n",
            "  (tdp): Dropout(p=0.2, inplace=False)\n",
            ")\n",
            "1400 140\n",
            "Epoch 1/10\n",
            "----------\n",
            "[1,     1] loss: 3.5315, Acc: 59.38\n",
            "[1,    41] loss: 2.2288, Acc: 57.93\n",
            "[1,    81] loss: 2.3039, Acc: 64.18\n",
            "[1,   121] loss: 2.2619, Acc: 68.07\n",
            "Training Loss: 2.511813 Acc: 69.60\n",
            "Epoch: 1, Val Loss: 2.1033, Acc: 82.20, F1_1: 82.20, F1_2: 87.70, F1_3: 75.20, F1_4: 78.10, F1_5: 90.00\n",
            "Epoch 2/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2,     1] loss: 2.0427, Acc: 79.69\n",
            "[2,    41] loss: 1.7113, Acc: 82.16\n",
            "[2,    81] loss: 1.4480, Acc: 82.47\n",
            "[2,   121] loss: 1.8147, Acc: 83.17\n",
            "Training Loss: 1.853256 Acc: 83.17\n",
            "Epoch: 2, Val Loss: 1.7068, Acc: 85.20, F1_1: 85.20, F1_2: 87.70, F1_3: 76.70, F1_4: 84.70, F1_5: 90.00\n",
            "Epoch 3/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3,     1] loss: 1.6850, Acc: 87.50\n",
            "[3,    41] loss: 1.5487, Acc: 85.25\n",
            "[3,    81] loss: 1.1644, Acc: 85.51\n",
            "[3,   121] loss: 1.5039, Acc: 85.85\n",
            "Training Loss: 1.613813 Acc: 85.78\n",
            "Epoch: 3, Val Loss: 1.5437, Acc: 87.10, F1_1: 87.10, F1_2: 88.90, F1_3: 80.60, F1_4: 85.30, F1_5: 90.00\n",
            "Epoch 4/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4,     1] loss: 1.5991, Acc: 84.38\n",
            "[4,    41] loss: 1.4567, Acc: 86.43\n",
            "[4,    81] loss: 1.0779, Acc: 86.69\n",
            "[4,   121] loss: 1.4257, Acc: 87.06\n",
            "Training Loss: 1.492588 Acc: 87.20\n",
            "Epoch: 4, Val Loss: 1.4816, Acc: 87.90, F1_1: 87.90, F1_2: 90.10, F1_3: 79.60, F1_4: 86.50, F1_5: 90.20\n",
            "Epoch 5/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5,     1] loss: 1.4720, Acc: 89.06\n",
            "[5,    41] loss: 1.3699, Acc: 87.69\n",
            "[5,    81] loss: 1.0035, Acc: 87.87\n",
            "[5,   121] loss: 1.2912, Acc: 88.00\n",
            "Training Loss: 1.414519 Acc: 87.99\n",
            "Epoch: 5, Val Loss: 1.4391, Acc: 88.30, F1_1: 88.30, F1_2: 89.80, F1_3: 80.10, F1_4: 86.50, F1_5: 91.30\n",
            "Epoch 6/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6,     1] loss: 1.3387, Acc: 92.19\n",
            "[6,    41] loss: 1.3129, Acc: 88.26\n",
            "[6,    81] loss: 0.9477, Acc: 88.41\n",
            "[6,   121] loss: 1.2136, Acc: 88.43\n",
            "Training Loss: 1.369079 Acc: 88.39\n",
            "Epoch: 6, Val Loss: 1.4221, Acc: 89.60, F1_1: 89.60, F1_2: 90.00, F1_3: 80.50, F1_4: 86.70, F1_5: 91.90\n",
            "Epoch 7/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7,     1] loss: 1.3485, Acc: 92.19\n",
            "[7,    41] loss: 1.2663, Acc: 88.76\n",
            "[7,    81] loss: 0.9369, Acc: 88.73\n",
            "[7,   121] loss: 1.1940, Acc: 88.75\n",
            "Training Loss: 1.341024 Acc: 88.80\n",
            "Epoch: 7, Val Loss: 1.4161, Acc: 88.80, F1_1: 88.80, F1_2: 90.30, F1_3: 80.70, F1_4: 86.80, F1_5: 91.90\n",
            "Epoch 8/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8,     1] loss: 1.3271, Acc: 87.50\n",
            "[8,    41] loss: 1.2684, Acc: 88.57\n",
            "[8,    81] loss: 0.9449, Acc: 88.70\n",
            "[8,   121] loss: 1.1739, Acc: 88.65\n",
            "Training Loss: 1.320170 Acc: 88.76\n",
            "Epoch: 8, Val Loss: 1.4088, Acc: 89.40, F1_1: 89.40, F1_2: 90.30, F1_3: 80.70, F1_4: 86.80, F1_5: 92.00\n",
            "Epoch 9/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9,     1] loss: 1.3025, Acc: 92.19\n",
            "[9,    41] loss: 1.2083, Acc: 89.18\n",
            "[9,    81] loss: 0.9076, Acc: 89.06\n",
            "[9,   121] loss: 1.1325, Acc: 89.08\n",
            "Training Loss: 1.303483 Acc: 89.13\n",
            "Epoch: 9, Val Loss: 1.4019, Acc: 89.40, F1_1: 89.40, F1_2: 90.40, F1_3: 81.10, F1_4: 87.00, F1_5: 92.30\n",
            "Epoch 10/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10,     1] loss: 1.2585, Acc: 89.06\n",
            "[10,    41] loss: 1.1373, Acc: 88.87\n",
            "[10,    81] loss: 0.8807, Acc: 89.16\n",
            "[10,   121] loss: 1.0975, Acc: 89.02\n",
            "Training Loss: 1.284678 Acc: 89.07\n",
            "Epoch: 10, Val Loss: 1.3967, Acc: 89.20, F1_1: 89.20, F1_2: 90.40, F1_3: 81.30, F1_4: 87.00, F1_5: 92.30\n",
            "Epoch complete in 8m 31s\n",
            "Training complete in 88m 21s\n",
            "--- 5301.000227689743 seconds ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
            "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation best epoch: 6, Val Loss: 1.4221, ACC: 89.60, F1: 89.60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:812: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ../aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
            "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test results:, Test Loss: 2.1456, ACC: 74.40, F1: 74.40, F2: 86.30, F3: 72.60, F4: 81.70, F5: 88.30\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader, Dataset, sampler\n",
        "tr_loader = DataLoader(tr_data, num_workers=4, batch_size=batch_size)\n",
        "vl_loader = DataLoader(vl_data, num_workers=2, batch_size=batch_size)\n",
        "ts_loader = DataLoader(ts_data, num_workers=2, batch_size=batch_size)\n",
        "\n",
        "## Model\n",
        "model = MMNetwork(dim, dim, 1)\n",
        "model.to(device)\n",
        "print(model)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), init_lr, betas=(0.99,0.98), weight_decay=1e-4)\n",
        "criterion = nn.BCELoss()\n",
        "num_train_steps = int(len(tr_data)/batch_size)*epochs\n",
        "num_warmup_steps = int(0.1*num_train_steps)\n",
        "print(num_train_steps, num_warmup_steps)    ## Print Number of total and warmup steps\n",
        "# scheduler = transformers.get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_train_steps)\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [5,10,15],gamma=0.5)\n",
        "# scheduler = None\n",
        "import time\n",
        "start_time = time.time()\n",
        "model_ft, best_epoch = train(model, optimizer, scheduler, num_epochs=epochs)\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "# torch.save(model_ft.state_dict(), 'saved_models/trained_model_%s.pt'%(args.net, vmodel))\n",
        "test_flag=False\n",
        "vl_loss, vl_acc, vl_f1, _, _, _, _ = evaluate(model_ft, vl_loader, test_flag)\n",
        "print('Validation best epoch: %d, Val Loss: %.4f, ACC: %.2f, F1: %.2f'%(best_epoch, np.round(vl_loss,4), vl_acc*100, vl_f1*100))\n",
        "test_flag=True\n",
        "ts_loss, ts_acc, ts_f1, ts_f2, ts_f3, ts_f4, ts_f5 = evaluate(model_ft, ts_loader, test_flag)\n",
        "print('Test results:, Test Loss: %.4f, ACC: %.2f, F1: %.2f, F2: %.2f, F3: %.2f, F4: %.2f, F5: %.2f'%(np.round(ts_loss,4), ts_acc*100, ts_f1*100, ts_f2*100, ts_f3*100, ts_f4*100, ts_f5*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Pxf13PzV6tCx"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}