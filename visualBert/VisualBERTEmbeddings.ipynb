{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKO7c7-1pavG",
        "outputId": "a82e07b3-40fa-4b49-f7c2-8d8ea94f6387"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu May 18 00:04:10 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P8     8W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "ZAffukltqAHT",
        "outputId": "dd11c4ef-b043-47a1-a085-c7918fdb187f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.0+cu118'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import torch\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywbPzK7bqGUb",
        "outputId": "cdf61718-eec4-4c76-b021-0be74398ebd2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "EodK9_SMqKfV"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install pyyaml==5.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJGK_4bgqQOz",
        "outputId": "f2c0b08b-eeda-4d7b-8cf1-9d0d2727c30d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/facebookresearch/detectron2.git@v0.5\n",
            "  Cloning https://github.com/facebookresearch/detectron2.git (to revision v0.5) to /tmp/pip-req-build-e55hortg\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-e55hortg\n",
            "  Running command git checkout -q 82a57ce0b70057685962b352535147d9a8118578\n",
            "  Resolved https://github.com/facebookresearch/detectron2.git to commit 82a57ce0b70057685962b352535147d9a8118578\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.5) (8.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from detectron2==0.5) (3.7.1)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.5) (2.0.6)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.5) (2.3.0)\n",
            "Collecting yacs>=0.1.6 (from detectron2==0.5)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from detectron2==0.5) (0.8.10)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from detectron2==0.5) (2.2.1)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.5) (4.65.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from detectron2==0.5) (2.12.2)\n",
            "Collecting fvcore<0.1.6,>=0.1.5 (from detectron2==0.5)\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting iopath<0.1.10,>=0.1.7 (from detectron2==0.5)\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from detectron2==0.5) (0.18.3)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.10/dist-packages (from detectron2==0.5) (1.4.2)\n",
            "Collecting omegaconf>=2.1 (from detectron2==0.5)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hydra-core>=1.1 (from detectron2==0.5)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting black==21.4b2 (from detectron2==0.5)\n",
            "  Downloading black-21.4b2-py3-none-any.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.0/131.0 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from black==21.4b2->detectron2==0.5) (8.1.3)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.10/dist-packages (from black==21.4b2->detectron2==0.5) (1.4.4)\n",
            "Requirement already satisfied: toml>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from black==21.4b2->detectron2==0.5) (0.10.2)\n",
            "Requirement already satisfied: regex>=2020.1.8 in /usr/local/lib/python3.10/dist-packages (from black==21.4b2->detectron2==0.5) (2022.10.31)\n",
            "Collecting pathspec<1,>=0.8.1 (from black==21.4b2->detectron2==0.5)\n",
            "  Downloading pathspec-0.11.1-py3-none-any.whl (29 kB)\n",
            "Collecting mypy-extensions>=0.4.3 (from black==21.4b2->detectron2==0.5)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.5) (1.22.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.5) (5.1)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.1->detectron2==0.5)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.1->detectron2==0.5) (23.1)\n",
            "Collecting portalocker (from iopath<0.1.10,>=0.1.7->detectron2==0.5)\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.5) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.5) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.5) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.5) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.5) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.5) (2.8.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.5) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.5) (1.54.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.5) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.5) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.5) (3.4.3)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.5) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.5) (2.27.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.5) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.5) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.5) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.5) (2.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.5) (0.40.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.5) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.5) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.5) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.5) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->detectron2==0.5) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.5) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.5) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.5) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.5) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.5) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2==0.5) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->detectron2==0.5) (3.2.2)\n",
            "Building wheels for collected packages: detectron2, fvcore, antlr4-python3-runtime\n",
            "  Building wheel for detectron2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for detectron2: filename=detectron2-0.5-cp310-cp310-linux_x86_64.whl size=7738141 sha256=ee865c06485d3e5852e3241233a3c75b3eaa95c660e0d1b5676d8c857355a86f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-8brlrbfs/wheels/90/18/04/b8a1ce45720c57c3fa0364dc489ef160ee2136361e994d3e81\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61405 sha256=00972c1dbd00335c3d8afb89c52d7942ae801eff7e3e61f42e3517f5a5804405\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=b4663ea1b71a448c3cfb8c8ccebd693a85c41f7295050e88f13206332ded3bf0\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "Successfully built detectron2 fvcore antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, yacs, portalocker, pathspec, omegaconf, mypy-extensions, iopath, hydra-core, black, fvcore, detectron2\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 black-21.4b2 detectron2-0.5 fvcore-0.1.5.post20221221 hydra-core-1.3.2 iopath-0.1.9 mypy-extensions-1.0.0 omegaconf-2.3.0 pathspec-0.11.1 portalocker-2.7.0 yacs-0.1.8\n"
          ]
        }
      ],
      "source": [
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git@v0.5'\n",
        "import torch, torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import cv2\n",
        "import numpy as np\n",
        "from copy import deepcopy\n",
        "from detectron2.modeling import build_model\n",
        "from detectron2.checkpoint import DetectionCheckpointer\n",
        "from detectron2.structures.image_list import ImageList\n",
        "from detectron2.data import transforms as T\n",
        "from detectron2.modeling.box_regression import Box2BoxTransform\n",
        "from detectron2.modeling.roi_heads.fast_rcnn import FastRCNNOutputs\n",
        "from detectron2.modeling.roi_heads.fast_rcnn import FastRCNNOutputLayers\n",
        "from detectron2.layers import ShapeSpec, batched_nms, cat, cross_entropy, nonzero_tuple\n",
        "from detectron2.structures.boxes import Boxes\n",
        "from detectron2.layers import nms\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.config import get_cfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9PXRwEJxqWnx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "441dd5fc-dd80-4469-be2a-a4c33e21db9c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YoyEeJJzrY1k"
      },
      "outputs": [],
      "source": [
        "cfg_path = \"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\"\n",
        "\n",
        "def load_config_and_model_weights(cfg_path):\n",
        "    cfg = get_cfg()\n",
        "    cfg.merge_from_file(model_zoo.get_config_file(cfg_path))\n",
        "\n",
        "    # ROI HEADS SCORE THRESHOLD\n",
        "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
        "\n",
        "    # Comment the next line if you're using 'cuda'\n",
        "    # cfg['MODEL']['DEVICE']='cpu'\n",
        "\n",
        "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(cfg_path)\n",
        "\n",
        "    return cfg\n",
        "\n",
        "cfg = load_config_and_model_weights(cfg_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFg0MvHe2hAB",
        "outputId": "cf8b331a-7651-4f3d-de48-d60eb5722bb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "model_final_a3ec72.pkl: 254MB [00:01, 200MB/s]                           \n",
            "WARNING:fvcore.common.checkpoint:The checkpoint state_dict contains keys that are not used by the model:\n",
            "  proposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\n"
          ]
        }
      ],
      "source": [
        "def get_model(cfg):\n",
        "    # build model\n",
        "    model = build_model(cfg)\n",
        "\n",
        "    # load weights\n",
        "    checkpointer = DetectionCheckpointer(model)\n",
        "    checkpointer.load(cfg.MODEL.WEIGHTS)\n",
        "\n",
        "    # eval mode\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "model = get_model(cfg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "-XKpgxNw3kce"
      },
      "outputs": [],
      "source": [
        "def prepare_image_inputs(cfg, img_list):\n",
        "    # Resizing the image according to the configuration\n",
        "    transform_gen = T.ResizeShortestEdge(\n",
        "                [cfg.INPUT.MIN_SIZE_TEST, cfg.INPUT.MIN_SIZE_TEST], cfg.INPUT.MAX_SIZE_TEST\n",
        "            )\n",
        "    img_list = [transform_gen.get_transform(img).apply_image(img) for img in img_list]\n",
        "\n",
        "    # Convert to C,H,W format\n",
        "    convert_to_tensor = lambda x: torch.Tensor(x.astype(\"float32\").transpose(2, 0, 1))\n",
        "\n",
        "    batched_inputs = [{\"image\":convert_to_tensor(img), \"height\": img.shape[0], \"width\": img.shape[1]} for img in img_list]\n",
        "\n",
        "    # Normalizing the image\n",
        "    num_channels = len(cfg.MODEL.PIXEL_MEAN)\n",
        "    pixel_mean = torch.Tensor(cfg.MODEL.PIXEL_MEAN).view(num_channels, 1, 1)\n",
        "    pixel_std = torch.Tensor(cfg.MODEL.PIXEL_STD).view(num_channels, 1, 1)\n",
        "    normalizer = lambda x: (x - pixel_mean) / pixel_std\n",
        "    images = [normalizer(x[\"image\"]) for x in batched_inputs]\n",
        "\n",
        "    # Convert to ImageList\n",
        "    images =  ImageList.from_tensors(images,model.backbone.size_divisibility)\n",
        "    \n",
        "    return images, batched_inputs\n",
        "#Example\n",
        "img1 = plt.imread('drive/MyDrive/MAMI_2022/training_images/1000.jpg')\n",
        "img_bgr1 = cv2.cvtColor(img1, cv2.COLOR_RGB2BGR)\n",
        "images, batched_inputs = prepare_image_inputs(cfg, [img_bgr1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "rEZpiOgS3q9g"
      },
      "outputs": [],
      "source": [
        "def get_features(model, images):\n",
        "    features = model.backbone(images.tensor.to(device))\n",
        "    return features\n",
        "\n",
        "features = get_features(model, images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "oochWc3TjrFP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68bbc651-e6fd-4174-f7d2-d6586f4015ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "VByQytSH30D0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94c248a2-b6c4-41a7-815b-dc6a714ffc86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        }
      ],
      "source": [
        "def get_proposals(model, images, features):\n",
        "    proposals, _ = model.proposal_generator(images, features)\n",
        "    return proposals\n",
        "\n",
        "proposals = get_proposals(model, images, features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Myt8TbV65Cfl"
      },
      "outputs": [],
      "source": [
        "def get_box_features(model, features, proposals):\n",
        "    features_list = [features[f] for f in ['p2', 'p3', 'p4', 'p5']]\n",
        "    box_features = model.roi_heads.box_pooler(features_list, [x.proposal_boxes for x in proposals])\n",
        "    box_features = model.roi_heads.box_head.flatten(box_features)\n",
        "    box_features = model.roi_heads.box_head.fc1(box_features)\n",
        "    box_features = model.roi_heads.box_head.fc_relu1(box_features)\n",
        "    box_features = model.roi_heads.box_head.fc2(box_features)\n",
        "\n",
        "    box_features = box_features.reshape(1, box_features.shape[0], box_features.shape[1]) # depends on your config and batch size\n",
        "    return box_features, features_list\n",
        "\n",
        "box_features, features_list = get_box_features(model, features, proposals)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "KOKXeIeDanHx"
      },
      "outputs": [],
      "source": [
        "def get_prediction_logits(model, features_list, proposals):\n",
        "    cls_features = model.roi_heads.box_pooler(features_list, [x.proposal_boxes for x in proposals])\n",
        "    cls_features = model.roi_heads.box_head(cls_features)\n",
        "    pred_class_logits, pred_proposal_deltas = model.roi_heads.box_predictor(cls_features)\n",
        "    return pred_class_logits, pred_proposal_deltas\n",
        "\n",
        "pred_class_logits, pred_proposal_deltas = get_prediction_logits(model, features_list, proposals)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "SZ1qQK136Lcq"
      },
      "outputs": [],
      "source": [
        "def get_box_scores(cfg, pred_class_logits, pred_proposal_deltas):\n",
        "    box2box_transform = Box2BoxTransform(weights=cfg.MODEL.ROI_BOX_HEAD.BBOX_REG_WEIGHTS)\n",
        "    smooth_l1_beta = cfg.MODEL.ROI_BOX_HEAD.SMOOTH_L1_BETA\n",
        "\n",
        "    outputs = FastRCNNOutputs(\n",
        "        box2box_transform,\n",
        "        pred_class_logits,\n",
        "        pred_proposal_deltas,\n",
        "        proposals,\n",
        "        smooth_l1_beta,\n",
        "    )\n",
        "\n",
        "    boxes = outputs.predict_boxes()\n",
        "    scores = outputs.predict_probs()\n",
        "    image_shapes = outputs.image_shapes\n",
        "\n",
        "    return boxes, scores, image_shapes\n",
        "\n",
        "boxes, scores, image_shapes = get_box_scores(cfg, pred_class_logits, pred_proposal_deltas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "c2AA9Fo2nOHV"
      },
      "outputs": [],
      "source": [
        "def get_output_boxes(boxes, batched_inputs, image_size):\n",
        "    proposal_boxes = boxes.reshape(-1, 4).clone()\n",
        "    scale_x, scale_y = (batched_inputs[\"width\"] / image_size[1], batched_inputs[\"height\"] / image_size[0])\n",
        "    output_boxes = Boxes(proposal_boxes)\n",
        "\n",
        "    output_boxes.scale(scale_x, scale_y)\n",
        "    output_boxes.clip(image_size)\n",
        "\n",
        "    return output_boxes\n",
        "\n",
        "output_boxes = [get_output_boxes(boxes[i], batched_inputs[i], proposals[i].image_size) for i in range(len(proposals))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "YrSU34Cvndtl"
      },
      "outputs": [],
      "source": [
        "def select_boxes(cfg, output_boxes, scores):\n",
        "    test_score_thresh = cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST\n",
        "    test_nms_thresh = cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST\n",
        "    cls_prob = scores.detach().cpu()\n",
        "    cls_boxes = output_boxes.tensor.detach().reshape(output_boxes.tensor.shape[0]//80,80,4).cpu()\n",
        "    max_conf = torch.zeros((cls_boxes.shape[0]))\n",
        "    for cls_ind in range(0, cls_prob.shape[1]-1):\n",
        "        cls_scores = cls_prob[:, cls_ind+1]\n",
        "        det_boxes = cls_boxes[:,cls_ind,:]\n",
        "        keep = np.array(nms(det_boxes, cls_scores, test_nms_thresh))\n",
        "        max_conf[keep] = torch.where(cls_scores[keep] > max_conf[keep], cls_scores[keep], max_conf[keep])\n",
        "    keep_boxes = torch.where(max_conf >= test_score_thresh)[0]\n",
        "    return keep_boxes, max_conf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "5K-gV_07nkta"
      },
      "outputs": [],
      "source": [
        "temp = [select_boxes(cfg, output_boxes[i], scores[i]) for i in range(len(scores))]\n",
        "keep_boxes, max_conf = [],[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Y92ALlLhnozd"
      },
      "outputs": [],
      "source": [
        "MIN_BOXES=10\n",
        "MAX_BOXES=100\n",
        "def filter_boxes(keep_boxes, max_conf, min_boxes, max_boxes):\n",
        "    if len(keep_boxes) < min_boxes:\n",
        "        keep_boxes = np.argsort(max_conf).numpy()[::-1][:min_boxes]\n",
        "    elif len(keep_boxes) > max_boxes:\n",
        "        keep_boxes = np.argsort(max_conf).numpy()[::-1][:max_boxes]\n",
        "    return keep_boxes\n",
        "\n",
        "keep_boxes = [filter_boxes(keep_box, mx_conf, MIN_BOXES, MAX_BOXES) for keep_box, mx_conf in zip(keep_boxes, max_conf)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "rv5axYIhvkCA"
      },
      "outputs": [],
      "source": [
        "def get_visual_embeds(box_features, keep_boxes):\n",
        "    return box_features[keep_boxes.copy()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "3G1hkbYTnsoM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "test_df = pd.read_csv('drive/MyDrive/training_images/training.csv', sep='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2i7VcZYpTpTW"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "bgr_images = []\n",
        "for image in tqdm(test_df.file_name):\n",
        "    img = plt.imread(f'/content/drive/MyDrive/training_images/{image}')\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "    bgr_images.append(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AB3IhpETxxXj"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "visual_embeds = []\n",
        "\n",
        "for image in tqdm(bgr_images):\n",
        "  # Convert Image to Model Input\n",
        "  image, batched_inputs = prepare_image_inputs(cfg, [image])\n",
        "\n",
        "  # Get ResNet+FPN features\n",
        "  features = get_features(model, image)\n",
        "\n",
        "  # Get region proposals from RPN\n",
        "  proposals = get_proposals(model, image, features)\n",
        "  \n",
        "  # Get Box Features for the proposals\n",
        "  box_features, features_list = get_box_features(model, features, proposals)\n",
        "\n",
        "  # Get prediction logits and boxes\n",
        "  pred_class_logits, pred_proposal_deltas = get_prediction_logits(model, features_list, proposals)\n",
        "\n",
        "  # Get FastRCNN scores and boxes\n",
        "  boxes, scores, image_shapes = get_box_scores(cfg, pred_class_logits, pred_proposal_deltas)\n",
        "\n",
        "  # Rescale the boxes to original image size\n",
        "  output_boxes = [get_output_boxes(boxes[i], batched_inputs[i], proposals[i].image_size) for i in range(len(proposals))]\n",
        "\n",
        "  # Select the Boxes using NMS\n",
        "  temp = [select_boxes(cfg, output_boxes[i], scores[i]) for i in range(len(scores))]\n",
        "  keep_boxes, max_conf = [], []\n",
        "  for keep_box, mx_conf in temp:\n",
        "    keep_boxes.append(keep_box)\n",
        "    max_conf.append(mx_conf)\n",
        "\n",
        "  # Limit the total number of boxes\n",
        "  keep_boxes = [filter_boxes(keep_box, mx_conf, MIN_BOXES, MAX_BOXES) for keep_box, mx_conf in zip(keep_boxes, max_conf)]\n",
        "\n",
        "  # Get the visual embedding\n",
        "  visual_embed = [torch.tensor(get_visual_embeds(box_feature, keep_box)).to(device) for box_feature, keep_box in zip(box_features, keep_boxes)]\n",
        "  visual_embeds.append(visual_embed[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "visual_embeds[505].shape\n"
      ],
      "metadata": {
        "id": "LA7AJhN4KzCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(visual_embeds)"
      ],
      "metadata": {
        "id": "A2hxWhA-K1-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "81hvZdrWK2Ii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEZ2iNiJTvs5"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTHa0P7iT19q"
      },
      "outputs": [],
      "source": [
        "import pickle \n",
        "\n",
        "with open('/content/drive/MyDrive/visual_embeds_train_1.pkl', 'wb') as f:\n",
        "  pickle.dump(visual_embeds, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uznHG-AlT5LK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJCsRKQDT-rj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "93a3rGqoUBxw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmvjM8mlUnAr"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}